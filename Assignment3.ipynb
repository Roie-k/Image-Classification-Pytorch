{"cells":[{"cell_type":"markdown","source":["# Assignment 3: Image Classification\n","\n","**Assignment Responsible**: Natalie Lang.\n","\n","In this assignment, we will build a convolutional neural network that can predict \n","whether two shoes are from the **same pair** or from two **different pairs**.\n","This kind of application can have real-world applications: for example to help\n","people who are visually impaired to have more independence.\n","\n","We will explore two convolutional architectures. While we will give you starter\n","code to help make data processing a bit easier, in this assignment you have a chance to build your neural network all by yourself. \n","\n","You may modify the starter code as you see fit, including changing the signatures of\n","functions and adding/removing helper functions. However, please make sure that we can understand what you are doing and why.\n"," "],"metadata":{"datalore":{"node_id":"rUtqtpumeGiU9qSgLSWIsq","type":"MD","hide_input_from_viewers":false,"hide_output_from_viewers":false,"report_properties":{}},"id":"7aRL0G4hwmR5"}},{"cell_type":"code","source":["import pandas\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F"],"execution_count":null,"outputs":[],"metadata":{"datalore":{"node_id":"Ah4GlVbbAIFKEVViWTgJBk","type":"CODE","hide_input_from_viewers":false,"hide_output_from_viewers":false,"report_properties":{}},"id":"gapNFtGhwmR8"}},{"cell_type":"markdown","source":["## Question 1. Data (20%)\n","\n","Download the data from https://www.dropbox.com/s/6gdcpmfddojrl8o/data.rar?dl=0.\n","\n","Unzip the file. There are three\n","main folders: `train`, `test_w` and `test_m`. Data in `train` will be used for\n","training and validation, and the data in the other folders will be used for testing.\n","This is so that the entire class will have the same test sets. The dataset is comprised of triplets of pairs, where each such triplet of image pairs was taken in a similar setting (by the same person).\n","\n","We've separated `test_w` and `test_m` so that we can track our model performance \n","for women's shoes and men's shoes separately. Each of the test sets contain images of either exclusively men's shoes or women's\n","shoes.\n","\n","Upload this data to Google Colab.\n","Then, mount Google Drive from your Google Colab notebook:"],"metadata":{"datalore":{"node_id":"iwTIBTefYd7Hx4VzEIUAjs","type":"MD","hide_input_from_viewers":false,"hide_output_from_viewers":false,"report_properties":{}},"id":"r33-BmsqwmR-"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[],"metadata":{"datalore":{"node_id":"eLDlDXFSkWiHx6Wbv7fwUE","type":"CODE","hide_input_from_viewers":false,"hide_output_from_viewers":false,"report_properties":{}},"id":"Yzsk2qsewmR_"}},{"cell_type":"markdown","source":["After you have done so, read this entire section \n","before proceeding. There are right and wrong ways of\n","processing this data. If you don't make the correct choices, you may find\n","yourself needing to start over.\n","Many machine learning projects fail because of the lack of care taken during\n","the data processing stage."],"metadata":{"datalore":{"node_id":"zxw4NgPD9PJ4BaiYqUpMfH","type":"MD","hide_input_from_viewers":false,"hide_output_from_viewers":false,"report_properties":{}},"id":"GqSsKgSQwmSA"}},{"cell_type":"markdown","source":["### Part (a) -- 8%\n","\n","Load the training and test data, and separate your training data into training and validation.\n","Create the numpy arrays `train_data`, `valid_data`, `test_w` and `test_m`, all of which should\n","be of shape `[*, 3, 2, 224, 224, 3]`. The dimensions of these numpy arrays are as follows:\n","\n","- `*` - the number of triplets allocated to train, valid, or test\n","- `3` - the 3 pairs of shoe images in that triplet\n","- `2` - the left/right shoes\n","- `224` - the height of each image\n","- `224` - the width of each image\n","- `3` - the colour channels\n","\n","So, the item `train_data[4,0,0,:,:,:]` should give us the left shoe of the first image of the fifth person.The item `train_data[4,0,1,:,:,:]`  should be the right shoe in the same pair. \n","The item `train_data[4,1,1,:,:,:]`  should be the right shoe in a different pair of that same person.\n","\n","When you first load the images using (for example) `plt.imread`, you may see a numpy array of shape\n","`[224, 224, 4]` instead of `[224, 224, 3]`. That last channel is what's called the alpha channel for transparent\n","pixels, and should be removed. \n","The pixel intensities are stored as an integer between 0 and 255.\n","Make sure you normlize your images, namely, divide the intensities by 255 so that you have floating-point values between 0 and 1. Then, subtract 0.5\n","so that the elements of `train_data`, `valid_data` and `test_data` are between -0.5 and 0.5.\n","**Note that this step actually makes a huge difference in training!**\n","\n","This function might take a while to run; it can takes several minutes to just\n","load the files from Google Drive.  If you want to avoid\n","running this code multiple times, you can save \n","your numpy arrays and load it later:\n","https://docs.scipy.org/doc/numpy/reference/generated/numpy.save.html"],"metadata":{"datalore":{"node_id":"0Y652e87nWFEZO8504Yb8y","type":"MD","hide_input_from_viewers":false,"hide_output_from_viewers":false,"report_properties":{}},"id":"mvC3-G3KwmSA"}},{"cell_type":"code","source":["# Your code goes here. Make sure it does not get cut off\n","# You can use the code below to help you get started. You're welcome to modify\n","# the code or remove it entirely: it's just here so that you don't get stuck\n","# reading files\n","\n","import glob\n","def get_organized_data(path):\n","  StudentDic={}\n","  SideDic={\"right\":0, \"left\":1}\n","  StudentList=[]\n","  Data=np.zeros(int(len(glob.glob(path))/6)*18*224*224).reshape((int(len(glob.glob(path))/6),3,2,224,224,3)) # Zeros right size np array\n","# sort the array by student id order\n","  for file in glob.glob(path):\n","      filename = file.split(\"/\")[-1]  \n","      StudentId = filename.split(\"_\")[0]\n","      StudentId = int(StudentId.split(\"u\")[1])\n","      if StudentId not in StudentList:\n","        StudentList.append(StudentId)\n","  StudentList=sorted(StudentList)\n","  for index in range(len(StudentList)):\n","    if StudentList[index] >99:\n","      StudentDic[\"u\" + str(StudentList[index])] = index\n","    elif StudentList[index] >9:\n","      StudentDic[\"u0\" + str(StudentList[index])] = index\n","    else:\n","      StudentDic[\"u00\" + str(StudentList[index])] = index\n","#getting the required parameters to index the np array, and getting all the images\n","  for file in glob.glob(path):\n","      filename = file.split(\"/\")[-1]   # get the name of the .jpg file\n","      [StudentId,TripletIndex,Side] = filename.split(\"_\")[:3]\n","      img = plt.imread(file)           # read the image as a numpy array\n","      Data[StudentDic[StudentId],int(TripletIndex)-1,SideDic[Side],:,:,:]=(img[:, :, :3]/255-0.5)\n","# np default is to save data as float, for this functions we will need to save the data as int (imshow)\n","  return Data\n","Data = get_organized_data(\"/content/gdrive/My Drive/Deep Learning/Assignment 3/train/*.jpg\") # train path\n","test_w = get_organized_data(\"/content/gdrive/My Drive/Deep Learning/Assignment 3/test_w/*.jpg\") # women test path\n","test_m = get_organized_data(\"/content/gdrive/My Drive/Deep Learning/Assignment 3/test_m/*.jpg\") # men test path\n","train_data=Data[:-10,:,:,:,:,:] # divide the data to train and validation, 10 last students to validation\n","valid_data=Data[-10:,:,:,:,:,:]"],"execution_count":null,"outputs":[],"metadata":{"datalore":{"node_id":"LRJHeH7PWHwVXflhOi59Ql","type":"CODE","hide_input_from_viewers":false,"hide_output_from_viewers":false,"report_properties":{}},"id":"rQvf0E9_wmSB"}},{"cell_type":"code","source":["# Run this code, include the image in your PDF submission\n","plt.figure()\n","plt.imshow(train_data[4,0,0,:,:,:]) # left shoe of first pair submitted by 5th student\n","plt.figure()\n","plt.imshow(train_data[4,0,1,:,:,:]) # right shoe of first pair submitted by 5th student\n","plt.figure()\n","plt.imshow(train_data[4,1,1,:,:,:]) # right shoe of second pair submitted by 5th student"],"execution_count":null,"outputs":[],"metadata":{"datalore":{"node_id":"k2HYqkkvYFFEYKNrSvH29r","type":"CODE","hide_input_from_viewers":false,"hide_output_from_viewers":false,"report_properties":{}},"id":"K2whcyyAwmSC"}},{"cell_type":"markdown","source":["### Part (b) -- 4%\n","\n","Since we want to train a model that determines whether two shoes come from the **same**\n","pair or **different** pairs, we need to create some labelled training data.\n","Our model will take in an image, either consisting of two shoes from the **same pair**\n","or from **different pairs**. So, we'll need to generate some *positive examples* with\n","images containing two shoes that *are* from the same pair, and some *negative examples* where \n","images containing two shoes that *are not* from the same pair.\n","We'll generate the *positive examples* in this part, and the *negative examples* in the next part.\n","\n","Write a function `generate_same_pair()` that takes one of the data sets that you produced\n","in part (a), and generates a numpy array where each pair of shoes in the data set is\n","concatenated together. In particular, we'll be concatenating together images of left\n","and right shoes along the **height** axis. Your function `generate_same_pair` should\n","return a  numpy array of shape `[*, 448, 224, 3]`.\n","\n","While at this stage we are working with numpy arrays, later on, we will need to convert this numpy array into a PyTorch tensor with shape\n","`[*, 3, 448, 224]`. For now, we'll keep the RGB channel as the last dimension since\n","that's what `plt.imshow` requires."],"metadata":{"datalore":{"node_id":"M31szoZzg8PFQL7hPBychA","type":"MD","hide_input_from_viewers":false,"hide_output_from_viewers":false,"report_properties":{}},"id":"HJC-orXQwmSD"}},{"cell_type":"code","source":["# Your code goes here\n","def generate_same_pair(data):\n","  result=np.zeros(int(len(data))*3*448*224*3).reshape((int(len(data)*3),448,224,3))\n","  index=0\n","  for student in data:\n","    for triplet in student:\n","      result[index,:,:,:]=triplet.reshape(448,224,3)\n","      index+=1\n","  return result\n","# Run this code, include the result with your PDF submission\n","print(train_data.shape) # if this is [N, 3, 2, 224, 224, 3]\n","print(generate_same_pair(train_data).shape) # should be [N*3, 448, 224, 3]\n","plt.imshow(generate_same_pair(train_data)[0]) # should show 2 shoes from the same pair"],"execution_count":null,"outputs":[],"metadata":{"datalore":{"node_id":"lZyhlAXsaXl7apZAHDfhTh","type":"CODE","hide_input_from_viewers":false,"hide_output_from_viewers":false,"report_properties":{}},"id":"_Q-tKVBBwmSE"}},{"cell_type":"markdown","source":["### Part (c) -- 4%\n","\n","Write a function `generate_different_pair()` that takes one of the data sets that\n","you produced in part (a), and generates a numpy array in the same shape as part (b).\n","However, each image will contain 2 shoes from a **different** pair, but submitted\n","by the **same student**. Do this by jumbling the 3 pairs of shoes submitted by \n","each student.\n","\n","Theoretically, for each person (triplet of pairs), there are 6 different combinations\n","of \"wrong pairs\" that we could produce. To keep our data set *balanced*, we will\n","only produce **three** combinations of wrong pairs per unique person.\n","In other words,`generate_same_pairs` and `generate_different_pairs` should\n","return the same number of training examples."],"metadata":{"datalore":{"node_id":"TB79Scbn0VYEEVsSHY70Ph","type":"MD","hide_input_from_viewers":false,"hide_output_from_viewers":false,"report_properties":{}},"id":"wAGSqIH-wmSE"}},{"cell_type":"code","source":["# Your code goes here\n","def generate_different_pair(data):\n","  result=np.zeros(int(len(data))*3*448*224*3).reshape((int(len(data)*3),448,224,3))\n","  index=0\n","  for student in data:\n","    for triplet in range(len(student)):\n","      result[index,:,:,:]=np.concatenate((student[triplet,0,:,:],student[(triplet+1)%3,1,:,:]))\n","      index+=1\n","  return result\n","# Run this code, include the result with your PDF submission\n","print(train_data.shape) # if this is [N, 3, 2, 224, 224, 3]\n","print(generate_different_pair(train_data).shape) # should be [N*3, 448, 224, 3]\n","plt.imshow(generate_different_pair(train_data)[0]) # should show 2 shoes from different pairs"],"execution_count":null,"outputs":[],"metadata":{"datalore":{"node_id":"ZfXCVLWwDPNrNaaA5zUIij","type":"CODE","hide_input_from_viewers":false,"hide_output_from_viewers":false,"report_properties":{}},"id":"jPmaWh2ywmSF"}},{"cell_type":"markdown","source":["### Part (d) -- 2%\n","\n","Why do we insist that the different pairs of shoes still come from the same\n","person?  (Hint: what else do images from the same person have in common?)"],"metadata":{"datalore":{"node_id":"8DMmQChXuB7p4NOWIW7gr6","type":"MD","hide_input_from_viewers":false,"hide_output_from_viewers":false,"report_properties":{}},"id":"27g4tc_LwmSF"}},{"cell_type":"markdown","source":["**Write your explanation here:**\n","\n","To avoid the impact of different backgrounds and only determine if the shoe is different from the other shoe itself, we gather data from the shoe, not the background."],"metadata":{"datalore":{"node_id":"UbnQwl5HaGWVL0DauFJ1q1","type":"MD","hide_input_from_viewers":false,"hide_output_from_viewers":false,"report_properties":{}},"id":"OkTyBoNswmSG"}},{"cell_type":"markdown","source":["### Part (e) -- 2%\n","\n","Why is it important that our data set be *balanced*? In other words suppose we created\n","a data set where 99% of the images are of shoes that are *not* from the same pair, and \n","1% of the images are shoes that *are* from the same pair. Why could this be a problem?"],"metadata":{"datalore":{"node_id":"bnw4w9lPJxnvE8iByxyx6N","type":"MD","hide_input_from_viewers":false,"hide_output_from_viewers":false,"report_properties":{}},"id":"cqrtFNECwmSG"}},{"cell_type":"markdown","source":["**Write your explanation here:**\n","\n","We need our data to be balanced in order to avoid only considering one choice. If almost all the shoes are different, then the model will always predict that the shoes are different, regardless of the images."],"metadata":{"datalore":{"node_id":"a3Y6dBvBPceY3pFEgj26Ul","type":"MD","hide_input_from_viewers":false,"hide_output_from_viewers":false,"report_properties":{}},"id":"_0P_WqBKwmSG"}},{"cell_type":"markdown","source":["## Question 2. Convolutional Neural Networks (25%)\n","\n","Before starting this question, we recommend reviewing the lecture and its associated example notebook on CNNs.\n","\n","In this section, we will build two CNN models in PyTorch.\n","\n","### Part (a) -- 9%\n","\n","Implement a CNN model in PyTorch called `CNN` that will take images of size\n","$3 \\times 448 \\times 224$, and classify whether the images contain shoes from\n","the same pair or from different pairs.\n","\n","The model should contain the following layers:\n","\n","- A convolution layer that takes in 3 channels, and outputs $n$ channels.\n","- A $2 \\times 2$ downsampling (either using a strided convolution in the previous step, or max pooling)\n","- A second convolution layer that takes in $n$ channels, and outputs $2\\cdot n$ channels.\n","- A $2 \\times 2$ downsampling (either using a strided convolution in the previous step, or max pooling)\n","- A third convolution layer that takes in $2\\cdot n$ channels, and outputs $4\\cdot n$ channels.\n","- A $2 \\times 2$ downsampling (either using a strided convolution in the previous step, or max pooling)\n","- A fourth convolution layer that takes in $4\\cdot n$ channels, and outputs $8\\cdot n$ channels.\n","- A $2 \\times 2$ downsampling (either using a strided convolution in the previous step, or max pooling)\n","- A fully-connected layer with 100 hidden units\n","- A fully-connected layer with 2 hidden units\n","\n","Make the variable $n$ a parameter of your CNN. You can use either $3 \\times 3$ or $5 \\times 5$\n","convolutions kernels. Set your padding to be `(kernel_size - 1) / 2` so that your feature maps\n","have an even height/width.\n","\n","Note that we are omitting in our description certain steps that practitioners will typically not mention,\n","like ReLU activations and reshaping operations. Use the example presented in class to figure out where they are."],"metadata":{"datalore":{"node_id":"GnbqCRovBTXHQex3jFzpCx","type":"MD","hide_input_from_viewers":false,"hide_output_from_viewers":false,"report_properties":{}},"id":"ePlEKwVgwmSH"}},{"cell_type":"code","source":["class CNN(nn.Module):\n","    def __init__(self,input_size, n,output_size, kernel_size=5):\n","        super(CNN, self).__init__()\n","        self.n = n\n","        self.hight=int((int((int((int((448-kernel_size+1)/2)-kernel_size+1)/2)-kernel_size+1)/2)-kernel_size+1)/2)\n","        self.width=int((int((int((int((224-kernel_size+1)/2)-kernel_size+1)/2)-kernel_size+1)/2)-kernel_size+1)/2)\n","        self.conv1 = nn.Conv2d(in_channels=3, out_channels=n, kernel_size=kernel_size)\n","        self.conv2 = nn.Conv2d(n, 2*n, kernel_size=kernel_size)\n","        self.conv3 = nn.Conv2d(2*n,4*n, kernel_size=kernel_size)\n","        self.conv4 = nn.Conv2d(4*n, 8*n, kernel_size=kernel_size)\n","        self.fc1 = nn.Linear(8*n*self.hight*self.width, 100)\n","        self.fc2 = nn.Linear(100, 2)\n","\n","    def forward(self, x, verbose=False):\n","        x = self.conv1(x)\n","        x = F.relu(x)\n","        x = F.max_pool2d(x, kernel_size=2)\n","        x = self.conv2(x)\n","        x = F.relu(x)\n","        x = F.max_pool2d(x, kernel_size=2)\n","        x = self.conv3(x)\n","        x = F.relu(x)\n","        x = F.max_pool2d(x, kernel_size=2)\n","        x = self.conv4(x)\n","        x = F.relu(x)\n","        x = F.max_pool2d(x, kernel_size=2)\n","        x = x.view(-1, 8*self.n*self.hight*self.width)\n","        x = self.fc1(x)\n","        x = F.relu(x)\n","        x = self.fc2(x)\n","        x = F.log_softmax(x, dim=1)\n","        return x\n","\n","    # TODO: complete this class"],"execution_count":null,"outputs":[],"metadata":{"datalore":{"node_id":"jxGo1T39YtsSQ4xPAAccnQ","type":"CODE","hide_input_from_viewers":false,"hide_output_from_viewers":false,"report_properties":{}},"id":"jWbrnCAowmSH"}},{"cell_type":"markdown","source":["### Part (b) -- 8%\n","\n","Implement a CNN model in PyTorch called `CNNChannel` that contains the same layers as\n","in the Part (a), but with one crucial difference: instead of starting with an image\n","of shape $3 \\times 448 \\times 224$, we will first manipulate the image so that the\n","left and right shoes images are concatenated along the **channel** dimension.\n","\n","<img src=\"https://drive.google.com/uc?id=1B59VE43X-6Dw3ag-9Ndn6vPEzbnFem8K\" width=\"400px\" />\n","\n","\n","Complete the manipulation in the `forward()` method (by slicing and using\n","the function `torch.cat`). The input to the first convolutional layer\n","should have 6 channels instead of 3 (input shape $6 \\times 224 \\times 224$).\n","\n","Use the same hyperparameter choices as you did in part (a), e.g. for the kernel size,\n","choice of downsampling, and other choices."],"metadata":{"datalore":{"node_id":"lQaEZOZX3xiJanLbc2dYzG","type":"MD","hide_input_from_viewers":false,"hide_output_from_viewers":false,"report_properties":{}},"id":"ihfbXe8xwmSI"}},{"cell_type":"code","source":["class CNNChannel(nn.Module):\n","    def __init__(self,input_size, n,output_size,kernel_size=3):\n","        super(CNNChannel, self).__init__()\n","        self.n = n\n","        self.width=int((int((int((int((224-kernel_size+1)/2)-kernel_size+1)/2)-kernel_size+1)/2)-kernel_size+1)/2)        \n","        self.conv1 = nn.Conv2d(in_channels=6, out_channels=n, kernel_size=kernel_size)\n","        self.conv2 = nn.Conv2d(n, 2*n, kernel_size=kernel_size)\n","        self.conv3 = nn.Conv2d(2*n,4*n, kernel_size=kernel_size)\n","        self.conv4 = nn.Conv2d(4*n, 8*n, kernel_size=kernel_size)\n","        self.fc1 = nn.Linear(8*n*self.width*self.width, 100)\n","        self.fc2 = nn.Linear(100, 2)\n","\n","    def forward(self, x, verbose=False):\n","        x1= x[:,:,:,:224]\n","        x2=x[:,:,:,224:]\n","        x= torch.cat((x1,x2),1)\n","        x = self.conv1(x)\n","        x = F.relu(x)\n","        x = F.max_pool2d(x, kernel_size=2)\n","        x = self.conv2(x)\n","        x = F.relu(x)\n","        x = F.max_pool2d(x, kernel_size=2)\n","        x = self.conv3(x)\n","        x = F.relu(x)\n","        x = F.max_pool2d(x, kernel_size=2)\n","        x = self.conv4(x)\n","        x = F.relu(x)\n","        x = F.max_pool2d(x, kernel_size=2)\n","        x = x.view(-1, 8*self.n*self.width*self.width)\n","        x = self.fc1(x)\n","        x = F.relu(x)\n","        x = self.fc2(x)\n","        x = F.log_softmax(x, dim=1)\n","        return x\n"],"execution_count":null,"outputs":[],"metadata":{"datalore":{"node_id":"T13UHOu20lstQ3dHVLOdpU","type":"CODE","hide_input_from_viewers":false,"hide_output_from_viewers":false,"report_properties":{}},"id":"YLhVgFg7wmSI"}},{"cell_type":"markdown","source":["## Part (c) -- 4%\n","\n","The two models are quite similar, and should have almost the same number of parameters.\n","However, one of these models will perform better, showing that architecture choices **do**\n","matter in machine learning. Explain why one of these models performs better."],"metadata":{"datalore":{"node_id":"YG9bWR0Tj7dizYEHsHpZkQ","type":"MD","hide_input_from_viewers":false,"hide_output_from_viewers":false,"report_properties":{}},"id":"nu1--NqmwmSI"}},{"cell_type":"markdown","source":["** Write your explanation here: **\n","\n","\n","Because most of the data in the images come from the closest neighboring pixels, the first model divides our images and misses much of the data. In the second model, we perform convolution between the two shoes, allowing us to better use the data from the different or the same shoe."],"metadata":{"datalore":{"node_id":"XrJzQq2UC9FHWXnMOzkmoE","type":"MD","hide_input_from_viewers":false,"hide_output_from_viewers":false,"report_properties":{}},"id":"C5Fjx4i0wmSJ"}},{"cell_type":"markdown","source":["## Part (d) -- 4%\n","\n","The function `get_accuracy` is written for you. You may need to modify this\n","function depending on how you set up your model and training.\n","\n","Unlike in the previous assignment, her we will separately compute the model accuracy on the\n","positive and negative samples.  Explain why we may wish to track the false positives and false negatives separately."],"metadata":{"datalore":{"node_id":"a6Jha01ZUSyIdFa5nGLJRO","type":"MD","hide_input_from_viewers":false,"hide_output_from_viewers":false,"report_properties":{}},"id":"ZqDxrWq0wmSJ"}},{"cell_type":"markdown","source":["**Write your explanation here:**"],"metadata":{"datalore":{"node_id":"JyAVv09fj4M8ureyVSs8zP","type":"MD","hide_input_from_viewers":false,"hide_output_from_viewers":false,"report_properties":{}},"id":"x33D7gRgwmSJ"}},{"cell_type":"code","source":["def get_accuracy(model, data, batch_size=50):\n","    \"\"\"Compute the model accuracy on the data set. This function returns two\n","    separate values: the model accuracy on the positive samples,\n","    and the model accuracy on the negative samples.\n","\n","    Example Usage:\n","\n","    >>> model = CNN() # create untrained model\n","    >>> pos_acc, neg_acc= get_accuracy(model, valid_data)\n","    >>> false_positive = 1 - pos_acc\n","    >>> false_negative = 1 - neg_acc\n","    \"\"\"\n","\n","    model.eval()\n","    n = data.shape[0]\n","\n","    data_pos = generate_same_pair(data)      # should have shape [n * 3, 448, 224, 3]\n","    data_neg = generate_different_pair(data) # should have shape [n * 3, 448, 224, 3]\n","\n","    pos_correct = 0\n","    for i in range(0, len(data_pos), batch_size):\n","        xs = torch.Tensor(data_pos[i:i+batch_size]).transpose(1, 3)\n","        zs = model(xs)\n","        pred = zs.max(1, keepdim=True)[1] # get the index of the max logit\n","        pred = pred.detach().numpy()\n","        pos_correct += (pred == 1).sum()\n","    \n","    neg_correct = 0\n","    for i in range(0, len(data_neg), batch_size):\n","        xs = torch.Tensor(data_neg[i:i+batch_size]).transpose(1, 3)\n","        zs = model(xs)\n","        pred = zs.max(1, keepdim=True)[1] # get the index of the max logit\n","        pred = pred.detach().numpy()\n","        neg_correct += (pred == 0).sum()\n","\n","    return pos_correct / (n * 3), neg_correct / (n * 3)"],"execution_count":null,"outputs":[],"metadata":{"datalore":{"node_id":"Ai7RVnaLEu9ZcPGiQLAwdY","type":"CODE","hide_input_from_viewers":false,"hide_output_from_viewers":false,"report_properties":{}},"id":"IKgSRX85wmSJ"}},{"cell_type":"markdown","source":["## Question 3. Training (40%)\n","\n","Now, we will write the functions required to train the model. \n","\n","Although our task is a binary classification problem, we will still use the architecture\n","of a multi-class classification problem. That is, we'll use a one-hot vector to represent\n","our target (like we did in the previous assignment). We'll also use `CrossEntropyLoss` instead of\n","`BCEWithLogitsLoss` (this is a standard practice in machine learning because\n","this architecture often performs better).\n","\n","### Part (a) -- 22%\n","\n","Write the function `train_model` that takes in (as parameters) the model, training data,\n","validation data, and other hyperparameters like the batch size, weight decay, etc.\n","This function should be somewhat similar to the training code that you wrote\n","in Assignment 2, but with a major difference in the way we treat our training data.\n","\n","Since our positive (shoes of the same pair) and negative (shoes of different pairs) training sets are separate, it is actually easier for\n","us to generate separate minibatches of positive and negative training data.\n"," In\n","each iteration, we'll take `batch_size / 2` positive samples and `batch_size / 2`\n","negative samples. We will also generate labels of 1's for the positive samples,\n","and 0's for the negative samples.\n","\n","Here is what your training function should include:\n","\n","- main training loop; choice of loss function; choice of optimizer\n","- obtaining the positive and negative samples\n","- shuffling the positive and negative samples at the start of each epoch\n","- in each iteration, take `batch_size / 2` positive samples and `batch_size / 2` negative samples\n","  as our input for this batch\n","- in each iteration, take `np.ones(batch_size / 2)` as the labels for the positive samples, and \n","  `np.zeros(batch_size / 2)` as the labels for the negative samples\n","- conversion from numpy arrays to PyTorch tensors, making sure that the input has dimensions $N \\times C \\times H \\times W$ (known as NCHW tensor), where $N$ is the number of images batch size, $C$ is the number of channels, $H$ is the height of the image, and $W$ is the width of the image. \n","- computing the forward and backward passes \n","- after every epoch, report the accuracies for the training set and validation set\n","- track the training curve information and plot the training curve\n","\n","It is also recommended to checkpoint your model (save a copy) after every epoch, as we did in Assignment 2."],"metadata":{"datalore":{"node_id":"kbfdUiNBVZAKCP9VJi4h3R","type":"MD","hide_input_from_viewers":false,"hide_output_from_viewers":false,"report_properties":{}},"id":"6LeO9XvxwmSK"}},{"cell_type":"code","source":["from os import truncate\n","#from torch._C import T\n","# Write your code here\n","def run_pytorch_gradient_descent(model,\n","                                 train_data=train_data,\n","                                 validation_data=valid_data,\n","                                 batch_size=10,\n","                                 learning_rate=0.001,\n","                                 weight_decay=0,\n","                                 max_iters=50,\n","                                 checkpoint_path=None):\n","    print(\"model: \", model)\n","    print(\"batch_size: \", batch_size)\n","    print(\"learning_rate: \", learning_rate)\n","    print(\"max_iters: \", max_iters)\n","    criterion = nn.CrossEntropyLoss()\n","    model.train()\n","    optimizer = optim.Adam(model.parameters(),\n","                           lr=learning_rate,\n","                           weight_decay=weight_decay)\n","    iters, losses = [], []\n","    same=True\n","    iters_sub, train_accs_pos, train_accs_neg, val_accs_pos, val_accs_neg = [], [] ,[], [], []\n","    diff_shoe=generate_different_pair(train_data)\n","    same_shoe=generate_same_pair(train_data)\n","    n = 0 # the number of iterations\n","    while True:\n","        reindex = np.random.permutation(len(diff_shoe))\n","        diff_shoe = diff_shoe[reindex]\n","        same_shoe = same_shoe[reindex]\n","        for i in range(0,len(train_data)*3,int(batch_size/2)):\n","            if (i + batch_size/2) > train_data.shape[0]*3:\n","              break\n","            xt=np.zeros(batch_size*3*448*224).reshape(batch_size,448,224,3)\n","            st=np.zeros(batch_size)\n","            xt[0:int(batch_size/2),:,:,:]=same_shoe[i:int(batch_size/2)+i,:,:,:]\n","            st[0:int(batch_size/2)]=np.ones(int(batch_size/2))\n","            xt[int(batch_size/2):batch_size,:,:,:]=diff_shoe[i:int(batch_size/2)+i,:,:,:]\n","            st[int(batch_size/2):batch_size]=np.zeros(int(batch_size/2))\n","            reindex = np.random.permutation(len(xt))\n","            xt = xt[reindex]\n","            st = st[reindex]\n","            # convert from numpy arrays to PyTorch tensors\n","            # Run this code, include the image in your PDF submission\n","            xt = torch.Tensor(xt).transpose(1, 3)\n","            st = torch.Tensor(st).long()\n","\n","            zs = model(xt)       # compute prediction logit\n","            loss =criterion(zs,st)                   # compute the total loss\n","            loss.backward()                     # compute updates for each parameter\n","            optimizer.step()                      # make the updates for each parameter\n","            optimizer.zero_grad()                    # a clean up step for PyTorch\n","            \n","\n","            # save the current training information\n","            iters.append(n)\n","            losses.append(float(loss)/batch_size)  # compute *average* loss\n","\n","            if n % 5 == 0:\n","                iters_sub.append(n)\n","                train_cost = float(loss.detach().numpy())\n","                [train_acc_pos,train_acc_neg] = get_accuracy(model, train_data)\n","                train_accs_pos.append(train_acc_pos)\n","                train_accs_neg.append(train_acc_neg)\n","                [val_acc_pos,val_acc_neg] = get_accuracy(model, valid_data)\n","                val_accs_pos.append(val_acc_pos)\n","                val_accs_neg.append(val_acc_neg)\n","                print(\"Iter %d. [Val pos Acc %.0f%%] [Val neg Acc %.0f%%] [Train pos Acc %.0f%%] [Train neg Acc %.0f%%] [Train loss %f]\" % (\n","                      n, val_acc_pos * 100,val_acc_neg * 100, train_acc_pos * 100,train_acc_neg * 100,train_cost))\n","\n","                if (checkpoint_path is not None) and n > 0:\n","                    torch.save(model.state_dict(), checkpoint_path.format(n))\n","\n","            # increment the iteration number\n","            n += 1\n","\n","            if n > max_iters:\n","                val_accs=(np.array(val_accs_neg)+np.array(val_accs_pos))/2\n","                train_accs=(np.array(train_accs_neg)+np.array(train_accs_pos))/2\n","                return iters, losses, iters_sub, list(train_accs), list(val_accs)\n","                \n","def plot_learning_curve(iters, losses, iters_sub, train_accs, val_accs):\n","    \"\"\"\n","    Plot the learning curve.\n","    \"\"\"\n","    plt.title(\"Learning Curve: Loss per Iteration\")\n","    plt.plot(iters, losses, label=\"Train\")\n","    plt.xlabel(\"Iterations\")\n","    plt.ylabel(\"Loss\")\n","    plt.show()\n","\n","    plt.title(\"Learning Curve: Accuracy per Iteration\")\n","    plt.plot(iters_sub, train_accs, label=\"Train\")\n","    plt.plot(iters_sub, val_accs, label=\"Validation\")\n","    plt.xlabel(\"Iterations\")\n","    plt.ylabel(\"Accuracy\")\n","    plt.legend(loc='best')\n","    plt.show()"],"execution_count":null,"outputs":[],"metadata":{"datalore":{"node_id":"L2nI4GH7pTXOpwudqEk3bK","type":"CODE","hide_input_from_viewers":false,"hide_output_from_viewers":false,"report_properties":{}},"id":"6qJSUMCxwmSK"}},{"cell_type":"markdown","source":["### Part (b) -- 6%\n","\n","Sanity check your code from Q3(a) and from Q2(a) and Q2(b) by showing that your models\n","can memorize a very small subset of the training set (e.g. 5 images).\n","You should be able to achieve 90%+ accuracy (don't forget to calculate the accuracy)\n","relatively quickly (within ~30 or so iterations).\n","\n","\n","(Start with the second network, it is easier to converge)\n","\n","Try to find the general parameters combination that work for each network, it can help you a little bit later."],"metadata":{"datalore":{"node_id":"T3MLhWiByKU88lW0K0Wcny","type":"MD","hide_input_from_viewers":false,"hide_output_from_viewers":false,"report_properties":{}},"id":"kKl6lDA2wmSL"}},{"cell_type":"code","source":["# Write your code here. Remember to include your results so that we can\n","# see that your model attains a high training accuracy. \n","n=6\n","input_size  = 448*224*3\n","output_size = 2 \n","kernel_size=3\n","model_cnn = CNNChannel(input_size, n, output_size,kernel_size)\n","learning_curve_info= run_pytorch_gradient_descent(model_cnn,\n","                                 train_data=train_data[0:5],\n","                                 validation_data=valid_data[0],\n","                                 batch_size=16,\n","                                 learning_rate=0.0008,\n","                                 weight_decay=0,\n","                                 max_iters=80,\n","                                 checkpoint_path=None)"],"execution_count":null,"outputs":[],"metadata":{"datalore":{"node_id":"RblRyNcBhuNmobyRC8AP2f","type":"CODE","hide_input_from_viewers":false,"hide_output_from_viewers":false,"report_properties":{}},"id":"3zp_EnL8wmSL"}},{"cell_type":"markdown","source":["### Part (c) -- 8%\n","\n","Train your models from Q2(a) and Q2(b). Change the values of a few \n","hyperparameters, including the learning rate, batch size, choice of $n$, and \n","the kernel size. You do not need to check all values for all hyperparameters. Instead, try to make big changes to see how each change affect your scores.\n","(try to start with finding a resonable learning rate for each network, that start changing the other parameters, the first network might need bigger $n$ and kernel size)\n","\n","In this section, explain how you tuned your hyperparameters."],"metadata":{"datalore":{"node_id":"4TadTAplN7b3VXs5demD8S","type":"MD","hide_input_from_viewers":false,"hide_output_from_viewers":false,"report_properties":{}},"id":"vlIYjJpswmSL"}},{"cell_type":"markdown","source":["**Write your explanation here:**\n","\n","Hyperparameter optimization in deep learning refers to the process of selecting the best set of hyperparameters for a deep learning model. Hyperparameters are values that are set before training a model and control the behavior of the model during training. Examples of hyperparameters include the learning rate, the number of hidden layers in the model, and the batch size.\n","\n","There are several ways to optimize hyperparameters in deep learning:\n","\n","Grid search: This involves specifying a range of values for each hyperparameter and training a model with every combination of hyperparameter values. The model with the best performance (as measured by a chosen metric, such as accuracy) is selected as the best model.\n","\n","Random search: This involves randomly sampling hyperparameter values from a specified range and training a model with those values. The process is repeated multiple times and the model with the best performance is selected as the best model.\n","\n","Bayesian optimization: This involves using a probabilistic model to guide the search for the optimal set of hyperparameters. The model is updated as new hyperparameter values are evaluated, allowing the search to converge on the best set of hyperparameters more quickly.\n","\n","Gradient-based optimization: This involves using gradient descent or a similar optimization algorithm to tune the hyperparameters by minimizing a loss function.\n","\n","Optimizing hyperparameters is an important step in the process of developing a deep learning model, as the choice of hyperparameters can significantly impact the model's performance. It is a good idea to invest time and effort in hyperparameter optimization to ensure that the model is able to achieve its best possible performance.\n","\n","We've used kind of \"Grid Search\", where we took a fixed lists of hyperparameters and we iterated over all of them. Then, we've picked the best result where the loss converged and we recieved the highest accuracy.\n","\n","*Important note: We could have run this model over many parameters, however we chose (as the hint recommend) a small set of differ parameters in order to see the change between them. Google colab crashed many times, we've tried to run all models in parallel, however the RAM wasn't big enough.\n","\n","In below, you'll be able to see all the results.\n","\n","For the CNN network, we found that a kernel size of 3x3, n=6, and a learning rate of 0.0008 worked best for us. For the CNNChannel, we found that a kernel size of 7x7, n=9, and a learning rate of 0.001 worked best for us. For both networks, we trained all the models with 2 different batch sizes (we chose in purpose high values): 100, and 250.\n","Where for CNN model, the best batch size was 100, and for CNNChannel the best batch size was 100.\n","For both models we've used a fixed number of 100 iteration, what we wanted to see is the change between different parameters, and due to colab crash we didn't changed the number of iteration and just used a high fixed number."],"metadata":{"datalore":{"node_id":"sx8yDo6Ya1UK1fsTRPcGoX","type":"MD","hide_input_from_viewers":false,"hide_output_from_viewers":false,"report_properties":{}},"id":"VZ_4cdplwmSM"}},{"cell_type":"code","source":["model_list = []\n","channel_model_list = []\n","\n","channel_n_list=[1,9]\n","channel_kernel_list=[3,7]  \n","\n","n_list = [6,15]\n","kernel_size_list = [3,10]\n","\n","input_size  = 448*224*3\n","output_size = 2  \n","\n","batch_size = [100,250]\n","learning_rate = [0.0008, 0.001]\n","max_iters = [100]\n","\n","print(f\"There are {len(n_list)*len(kernel_size_list)*len(batch_size)*len(learning_rate)*len(max_iters)*2} models\")\n","\n","for i in range(len(n_list)):\n","  for j in range(len(kernel_size_list)):\n","\n","    channel_model_cnn = CNNChannel(input_size, channel_n_list[i], output_size,channel_kernel_list[j])\n","    model_cnn = CNN(input_size, n_list[i], output_size,kernel_size_list[j]) \n","\n","    for batch in batch_size:\n","      for lr in learning_rate:\n","        for iter in max_iters:\n","\n","          cnn = run_pytorch_gradient_descent(model = model_cnn,batch_size = batch,learning_rate = lr,max_iters = iter,\n","                                             checkpoint_path='/content/gdrive/My Drive/Deep Learning/Assignment 3/ckptCNN-{}.pk')\n","          \n","          channel = run_pytorch_gradient_descent(model = channel_model_cnn,batch_size = batch,learning_rate = lr,max_iters = iter,\n","                                             checkpoint_path='/content/gdrive/My Drive/Deep Learning/Assignment 3/ckptCNN-{}.pk')\n","          \n","          model_list.append(cnn)\n","          channel_model_list.append(channel)\n","\n","          print(\"n = \", i,\"kernel = \", j,\"batch size = \", batch,\"learning_rate = \", lr,\"iter = \", iter)"],"metadata":{"id":"qCHgK3vsoCyH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pickle\n","\n","with open('/content/gdrive/My Drive/Deep Learning/Assignment 3/channel_model_list.pkl', 'wb') as f:\n","   pickle.dump(channel_model_list, f)\n","\n","# with open('/content/gdrive/My Drive/Deep Learning/Assignment 3/model_list.pkl', 'rb') as f:\n","#    model_list = pickle.load(f)"],"metadata":{"id":"gmxmsdFXV6zG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i in range(len(channel_model_list)):\n","  print(i)\n","\n","  plot_learning_curve(*channel_model_list[i])"],"metadata":{"id":"adeKGHgavqM2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Part (d) -- 4%\n","\n","Include your training curves for the **best** models from each of Q2(a) and Q2(b).\n","These are the models that you will use in Question 4."],"metadata":{"datalore":{"node_id":"eYtZ7RdUjC9dMxGAkMDsdM","type":"MD","hide_input_from_viewers":false,"hide_output_from_viewers":false,"report_properties":{}},"id":"17UONqQ_wmSM"}},{"cell_type":"code","source":["# Include the training curves for the two models.\n","plot_learning_curve(*channel_model_list[14]) # learning curve for CnnChannel best model\n","plot_learning_curve(*model_list[1]) # learning curve for CNN best model"],"execution_count":null,"outputs":[],"metadata":{"datalore":{"node_id":"iPQ4xH1AfdSIqyPSU8swWn","type":"CODE","hide_input_from_viewers":false,"hide_output_from_viewers":false,"report_properties":{}},"id":"g8pQ-eoIwmSM"}},{"cell_type":"code","source":["n=9\n","kernel_size=7\n","input_size = 448*224*3\n","output_size = 2\n","model_cnn = CNNChannel(input_size, n, output_size,kernel_size)\n","bestchannel= run_pytorch_gradient_descent(model_cnn,train_data=train_data,validation_data=valid_data,batch_size=100,learning_rate=0.001,weight_decay=0,max_iters=100,\n","checkpoint_path='/content/gdrive/My Drive/Deep Learning/Assignment 3/Best_model-{}.pk')"],"metadata":{"id":"pik5xZrRjOn0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_learning_curve(*bestchannel)"],"metadata":{"id":"vXI9f0Gvkfwq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Question 4. Testing (15%)\n","\n","### Part (a) -- 7%\n","\n","Report the test accuracies of your **single best** model,\n","separately for the two test sets.\n","Do this by choosing the  model\n","architecture that produces the best validation accuracy. For instance,\n","if your model attained the\n","best validation accuracy in epoch 12, then the weights at epoch 12 is what you should be using\n","to report the test accuracy."],"metadata":{"datalore":{"node_id":"3iFnqN0aCYs9F1IMbIm4da","type":"MD","hide_input_from_viewers":false,"hide_output_from_viewers":false,"report_properties":{}},"id":"n7cdakdxwmSN"}},{"cell_type":"code","source":["# Write your code here. Make sure to include the test accuracy in your report\n","input_size  = 448*224*3\n","output_size = 2  \n","model_cnn = CNNChannel(input_size, n = 9, output_size = 2,kernel_size = 7)\n","model_cnn.load_state_dict(torch.load('/content/gdrive/My Drive/Deep Learning/Assignment 3/Best_model-60.pk'))\n","data_pos = generate_same_pair(test_m)  \n","data_neg = generate_different_pair(test_m)\n","GoodPredMenPair=[]\n","BadPredMenPair=[]\n","FGoodPredMenPair=[]\n","FBadPredMenPair=[]\n","xs = torch.Tensor(data_pos).transpose(1, 3)\n","zs = model_cnn(xs)\n","pred = zs.max(1, keepdim=True)[1] # get the index of the max logit\n","pred = pred.detach().numpy()\n","\n","for i in range(len(pred)):\n","  if pred[i]==1:\n","    GoodPredMenPair.append(data_pos[i])\n","  else:\n","    BadPredMenPair.append(data_pos[i])\n","\n","xs = torch.Tensor(data_neg).transpose(1, 3)\n","zs = model_cnn(xs)\n","pred = zs.max(1, keepdim=True)[1] # get the index of the max logit\n","pred = pred.detach().numpy()\n","\n","for i in range(len(pred)):\n","  if pred[i]==0:\n","    FGoodPredMenPair.append(data_neg[i])\n","  else:\n","    FBadPredMenPair.append(data_neg[i])\n","\n","data_pos = generate_same_pair(test_w) \n","data_neg = generate_different_pair(test_w)\n","GoodPredWomenPair=[]\n","BadPredWomenPair=[]\n","xs = torch.Tensor(data_pos).transpose(1, 3)\n","zs = model_cnn(xs)\n","pred = zs.max(1, keepdim=True)[1] # get the index of the max logit\n","pred = pred.detach().numpy()\n","\n","for i in range(len(pred)):\n","  if pred[i]==1:\n","    GoodPredWomenPair.append(data_pos[i])\n","  else:\n","    BadPredWomenPair.append(data_pos[i])\n","FGoodPredWomenPair=[]\n","FBadPredWomenPair=[]\n","xs = torch.Tensor(data_neg).transpose(1, 3)\n","zs = model_cnn(xs)\n","pred = zs.max(1, keepdim=True)[1] # get the index of the max logit\n","pred = pred.detach().numpy()\n","\n","for i in range(len(pred)):\n","  if pred[i]==0:\n","    FGoodPredWomenPair.append(data_neg[i])\n","  else:\n","    FBadPredWomenPair.append(data_neg[i])\n","    \n","print(get_accuracy(model_cnn, test_m, batch_size=1))\n","print(get_accuracy(model_cnn, test_w, batch_size=1))"],"execution_count":null,"outputs":[],"metadata":{"datalore":{"node_id":"uln1l5ZEsiwFS3uHpIJRAo","type":"CODE","hide_input_from_viewers":false,"hide_output_from_viewers":false,"report_properties":{}},"id":"jlzzKPh_wmSN"}},{"cell_type":"markdown","source":["### Part (b) -- 4%\n","\n","Display one set of men's shoes that your model correctly classified as being\n","from the same pair.\n","\n","If your test accuracy was not 100% on the men's shoes test set,\n","display one set of inputs that your model classified incorrectly."],"metadata":{"datalore":{"node_id":"ZaVPFbiMudWZnO4yQUIDBF","type":"MD","hide_input_from_viewers":false,"hide_output_from_viewers":false,"report_properties":{}},"id":"fXuEzI4OwmSN"}},{"cell_type":"code","source":["plt.figure()\n","plt.imshow(((GoodPredMenPair[0]+0.5)*255).astype(int))  # TRUE Positive prediction of men shoe pair\n","plt.figure()\n","plt.imshow(((BadPredMenPair[0]+0.5)*255).astype(int)) # False Negetive prediction of men shoe pair"],"metadata":{"id":"garOfQ54k3AD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","### Part (c) -- 4%\n","\n","Display one set of women's shoes that your model correctly classified as being\n","from the same pair.\n","\n","If your test accuracy was not 100% on the women's shoes test set,\n","display one set of inputs that your model classified incorrectly."],"metadata":{"datalore":{"node_id":"xcD7PufblyM5LYpQGQMrrb","type":"MD","hide_input_from_viewers":false,"hide_output_from_viewers":false,"report_properties":{}},"id":"oKyagICwwmSO"}},{"cell_type":"code","source":["plt.figure()\n","plt.imshow(((GoodPredWomenPair[0]+0.5)*255).astype(int)) # TRUE Positive prediction of Women shoe pair \n","plt.figure()\n","plt.imshow(((BadPredWomenPair[0]+0.5)*255).astype(int)) # False Negetive prediction of Women shoe pair"],"metadata":{"id":"XBdzieirk8ZQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We can see that the accuracy for men's shoes was lower at 83.3% compared to the accuracy for women's shoes at 88.3%.\n","\n","We identified sneakers as a single pair among the men's shoes, and we identified running shoes as a separate pair. It's possible that there are more sneakers than other types of shoes in the dataset.\n","\n","For the women's shoes, we identified high heel shoes well, but we had difficulty identifying sandals as a separate pair. This may be because there are few sandals in the training dataset.\n","\n","If our dataset had more sandals and high boots, it's likely that the accuracy for those types of shoes would increase as well."],"metadata":{"id":"t5ILNMkk1gGY"}}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"datalore":{"version":1,"computation_mode":"JUPYTER","package_manager":"pip","base_environment":"default","packages":[]},"colab":{"private_outputs":true,"provenance":[]},"accelerator":"GPU","gpuClass":"standard","language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}